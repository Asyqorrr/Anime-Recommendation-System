# -*- coding: utf-8 -*-
"""anime recommendation prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FnA08o7hbVZu3esy-qYigeLJuWYBfiI8
"""

! pip install -q kaggle

# from google.colab import files
# files.upload()

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle datasets download -d CooperUnion/anime-recommendations-database

"""# **Mengextract file zip**
Mengekstrak file zip dari kaggle yang sudah di download ke directory /content
"""

# extract zip
import zipfile, os
zip_path = '/content/anime-recommendations-database.zip'

# select zipfile
zip_ref = zipfile.ZipFile(zip_path, 'r') # 'r' adalah read only
zip_ref.extractall('/content')               # extract di /tmp
zip_ref.close()

"""# **Melihat isi dataset**
Melihat isi dataset menggunakan Pandas beserta melihat isi df.info()

## Anime
"""

import pandas as pd

anime = pd.read_csv('anime.csv')
anime.info()

anime.describe()

print('Jumlah data banyaknya anime: ', len(anime.anime_id.unique()))

print('Banyak Genre: ', len(anime.genre.unique()))

print('Tipe-tipe anime: ', anime.type.unique())

print('Variasi banyak episode anime: ', len(anime.episodes.unique()))

print('Variasi banyak member anime: ', len(anime.members.unique()))

"""## Rating"""

rating = pd.read_csv('rating.csv')
rating.info()

rating.tail(3)

rating.describe()

print('Jumlah data banyaknya anime: ', len(anime.anime_id.unique()))
print('Jumlah data banyaknya rating: ', len(rating.anime_id.unique()))

"""# **Data Preprocessing**

## Anime.csv
"""

import numpy as np

anime.head(5)

# cek null values anime

print(anime.isnull().sum())

# Hapus null values pada anime
anime = anime.dropna()

anime.describe()

# Hapus kolom members

anime = anime.drop('members', axis=1)

# Hapus kolom rating

anime = anime.drop('rating', axis=1)

# Hapus kolom episodes

anime = anime.drop('episodes', axis=1)

# Hapus kolom type

anime = anime.drop('type', axis=1)

"""## Rating"""

# Rubah nilai -1 yang terdapat dalam rating menjadi null

rating = rating.replace(-1, np.nan)

# cek null values di rating

print(rating.isnull().sum())

# Hapus null values di rating

rating = rating.dropna()

# Menggabungkan kolom animeID 
anime_all = np.concatenate((
    anime.anime_id.unique(),
    rating.anime_id.unique()
))

# Mengurutkan data dan menghapus data yang sama
anime_all = np.sort(np.unique(anime_all))

print('Jumlah seluruh data anime berdasarkan anime_id: ', len(anime_all))

# Definisikan banyak user yang memberikan rating
user_all = rating.user_id.unique()

# Menghapus data yang sama lalu mengurutkan
user_all = np.sort(np.unique(user_all))

print('Jumlah seluruh user: ', len(user_all))

rating

"""## Mengetahui Jumlah Rating """

rate_anime = pd.merge(rating, anime, on='anime_id', how='left')
rate_anime

# cek missing value dengan isnull()

rate_anime.isnull().sum()

# Menghitung jumlah rating lalu gabungkan berdasarkan animeID
rate_anime.groupby('anime_id').sum()

"""## Menggabungkan data dengan fitur nama anime"""

# Definisikan dataframe rating ke dalam variabel all_anime_rate
all_anime_rate = rating
all_anime_rate

all_anime_name = pd.merge(all_anime_rate, anime[['anime_id','name']], on='anime_id', how='left')
all_anime_name

"""## Menggabungkan data dengan fitur genre anime"""

# Buat dataframe khusus untuk kolom anime_id dan type
genre = anime[["anime_id", "genre"]]
genre

all_anime = pd.merge(all_anime_name, genre, on='anime_id', how='left')

"""# Data Preparation"""

# Mengecek missing value pada dataframe all_resto
all_anime.isnull().sum()

"""## Mengatasi Missing Value"""

all_anime_clean = all_anime.dropna()
all_anime_clean

all_anime_clean.isnull().sum()

# Hapus data duplikat pada variabel all_anime_clean dan define ke preparation
preparation = all_anime_clean.drop_duplicates('anime_id')
preparation

"""## Konversi data ke list"""

# Konversi data series 'anime_id' ke bentuk list
anime_id = preparation['anime_id'].tolist()

# konversi data series 'name' ke bentuk list
anime_name = preparation['name'].tolist()

# konversi data series 'genre' ke bentuk list
genre = preparation['genre'].tolist()


print(len(anime_id))
print(len(anime_name))
print(len(genre))

"""## Buat dictionary dari list"""

# Membuat dictionary untuk data anime_id, anime_name, genre, dan tipe
anime_dict = pd.DataFrame({
    'id': anime_id,
    'anime_name': anime_name,
    'genre': genre,
})

anime_dict

"""# **Model Development dengan Content Based Filtering**"""

data = anime_dict
data.sample(5)

len(data.genre.unique())

"""## TF-IDF Vectorizer"""

from sklearn.feature_extraction.text import TfidfVectorizer

# inisialisasi tf-idf
tf = TfidfVectorizer()

# melakukan perhitungan idf pada data type
tfidf_matrix = tf.fit_transform(data['genre']) 

# melihat ukuran matix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan jenis masakan
# Baris diisi dengan nama resto

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names(),
    index=data.anime_name
).sample(22, axis=1).sample(10, axis=0)

"""## Cosine Similarity"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama anime
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['anime_name'], columns=data['anime_name'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix pada setiap resto
cosine_sim_df.sample(6, axis=1).sample(10, axis=0)

"""## Mendapatkan Rekomendasi"""

def anime_recommendations(nama_anime, similarity_data=cosine_sim_df, items=data[['anime_name', 'genre']], k=5):
    
 
 
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_anime].to_numpy().argpartition(
        range(-1, -k, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_anime, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

data[data.anime_name.eq('Naruto')]

data.sample(10)

input = 'Bleach'
recom = anime_recommendations(input, k=5)
recom

"""Dari hasil rekomendasi diatas diketahui bahwa Naruto termasuk dalam tipe anime TV, dari 5 item yang direkomendasikan, 5 item memiliki kategori TV (similar) artinya, precision sistem kita sebesar 100%

# Evaluation
"""

def jaccard_set(list_genre, list_genre_prediksi):
    intersection = len(list(set(list_genre).intersection(list_genre_prediksi)))
    union = (len(list_genre) + len(list_genre_prediksi)) - intersection
    return float(intersection) / union

genre_list = anime[anime.name.eq(input)]['genre'].values.tolist()

# Memisahkan genre satu sama lainnya

def iterate(list):
  for x in list:
    return x.split(',')

anime_genre = iterate(genre_list)

print('sebelum dipisah: ', genre_list)
print('setelah dipisah: ', anime_genre)

predict_genre = anime_recommendations(input)['genre'].values

def jaccard_value_total(anime_genre, predict_genre):
  total_jaccard_value = 0
  result = 0

  for i in range(len(predict_genre)):
    genre = predict_genre[i].split(',')
    jaccard_value = jaccard_set(anime_genre, genre)
    total_jaccard_value += jaccard_value
    result = total_jaccard_value / len(predict_genre)
    
  return result

jaccard_value_total(anime_genre, predict_genre)

# precision = (5/5)*100
# print("Presisi dari model adalah sebesar {}%". format(precision))